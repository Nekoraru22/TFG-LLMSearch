
@misc{thomas_janssen_build_2024,
	title = {Build a {RAG} in 10 minutes! {\textbar} {Python}, {ChromaDB}, {OpenAI}},
	url = {https://www.youtube.com/watch?v=JfSmffOyV-8},
	urldate = {2025-04-22},
	author = {{Thomas Janssen}},
	month = aug,
	year = {2024},
}

@misc{multani_mickymultanirag-chromadb-mistral7b_2025,
	title = {mickymultani/{RAG}-{ChromaDB}-{Mistral7B}},
	url = {https://github.com/mickymultani/RAG-ChromaDB-Mistral7B},
	abstract = {RAG (Retrievel Augmented Generation) implementation using ChromaDB, Mistral-7B-Instruct-v0.1 and gte-base for embeddings.},
	urldate = {2025-04-22},
	author = {Multani, Micky},
	month = feb,
	year = {2025},
	note = {original-date: 2023-10-01T19:25:31Z},
}

@misc{noauthor_que_nodate,
	title = {¿{Qué} es {RAG}?: explicación de la {IA} de generación aumentada por recuperación, {AWS}},
	shorttitle = {¿{Qué} es {RAG}?},
	url = {https://aws.amazon.com/es/what-is/retrieval-augmented-generation/},
	abstract = {Qué es la Retrieval-Augmented Generation (RAG, generación aumentada por recuperación), cómo y por qué las empresas usan IA de RAG y cómo usar RAG con AWS.},
	language = {es-ES},
	urldate = {2025-04-07},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\ZWGN2CK7\\retrieval-augmented-generation.html:text/html},
}

@misc{noauthor_lmstudio-python_nodate,
	title = {lmstudio-python ({Python} {SDK}) {\textbar} {LM} {Studio} {Docs}},
	url = {https://lmstudio.ai/docs/python},
	abstract = {Getting started with LM Studio's Python SDK},
	language = {en},
	urldate = {2025-03-31},
	journal = {LM Studio - Docs},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\AHQWUCLT\\python.html:text/html},
}

@misc{noauthor_lm_nodate,
	title = {{LM} {Studio} - {Discover}, download, and run local {LLMs}},
	url = {https://lmstudio.ai},
	abstract = {Run Llama, Gemma 3, DeepSeek locally on your computer.},
	language = {en},
	urldate = {2025-03-31},
	journal = {LM Studio},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\ZVYYKYXY\\lmstudio.ai.html:text/html},
}

@misc{noauthor_mongodb_nodate,
	title = {{MongoDB} {Atlas}: {Cloud} {Document} {Database}},
	shorttitle = {{MongoDB} {Atlas}},
	url = {https://www.mongodb.com/es/lp/cloud/atlas/try4},
	abstract = {Cloud-hosted MongoDB service on AWS, Azure, and GCP},
	language = {es},
	urldate = {2025-02-23},
	journal = {MongoDB},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\C6QX8EJD\\try4.html:text/html},
}

@misc{noauthor_sqlite_nodate,
	title = {{SQLite} {Home} {Page}},
	url = {https://www.sqlite.org/},
	urldate = {2025-02-23},
	file = {SQLite Home Page:C\:\\Users\\Neko\\Zotero\\storage\\WPYU9XRI\\www.sqlite.org.html:text/html},
}

@misc{noauthor_watchdog_nodate,
	title = {watchdog: {Filesystem} events monitoring},
	copyright = {OSI Approved :: Apache Software License},
	shorttitle = {watchdog},
	url = {https://github.com/gorakhargosh/watchdog},
	urldate = {2025-02-23},
	keywords = {DirectorySnapshot, filesystem,, FSEvents,, inotify,, kqueue,, monitor,, monitoring,, polling,, python,, ReadDirectoryChangesW,, Software Development - Libraries, System - Filesystems, System - Monitoring, Utilities},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\HBVV8XXY\\watchdog.html:text/html},
}

@misc{noauthor_home_nodate,
	title = {Home},
	url = {https://airflow.apache.org/},
	abstract = {Platform created by the community to programmatically author, schedule and monitor workflows.},
	language = {en},
	urldate = {2025-02-23},
	journal = {Apache Airflow},
	annote = {Airflow
},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\ALQ9QV27\\airflow.apache.org.html:text/html},
}

@misc{noauthor_apache_nodate,
	title = {Apache {Kafka}},
	url = {https://kafka.apache.org/documentation/},
	abstract = {Apache Kafka: A Distributed Streaming Platform.},
	language = {en},
	urldate = {2025-02-23},
	journal = {Apache Kafka},
	annote = {Kafka
},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\DCHAER4Z\\documentation.html:text/html},
}

@misc{noauthor_best_2024,
	title = {Best {ML} {Workflow} and {Pipeline} {Orchestration} {Tools} 2024},
	url = {https://dagshub.com/blog/best-machine-learning-workflow-and-pipeline-orchestration-tools/},
	abstract = {Explore the top ML workflow and pipeline tools, including tools from Netflix, to enhance your data science projects' efficiency and impact.},
	language = {en},
	urldate = {2025-02-23},
	journal = {DagsHub Blog},
	month = apr,
	year = {2024},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\HLKWT5A4\\best-machine-learning-workflow-and-pipeline-orchestration-tools.html:text/html},
}

@misc{suspicious_dress_350_airflow_2024,
	type = {Reddit {Post}},
	title = {Airflow vs {Dagster} vs {Prefect} vs ?},
	url = {https://www.reddit.com/r/dataengineering/comments/1cxyvqk/airflow_vs_dagster_vs_prefect_vs/},
	urldate = {2025-02-23},
	journal = {r/dataengineering},
	author = {Suspicious\_Dress\_350},
	month = may,
	year = {2024},
	file = {Reddit Post Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\M8TSAM3C\\airflow_vs_dagster_vs_prefect_vs.html:text/html},
}

@misc{noauthor_home_0800,
	title = {Home},
	url = {https://docs.docker.com/},
	abstract = {Docker Documentation is the official Docker library of resources, manuals, and guides to help you containerize applications.},
	language = {en},
	urldate = {2025-02-23},
	journal = {Docker Documentation},
	year = {0800},
	annote = {Docker
},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\A55A6T9A\\docs.docker.com.html:text/html},
}

@misc{noauthor_pythonic_nodate,
	title = {Pythonic, {Modern} {Workflow} {Orchestration} {For} {Resilient} {Data} {Platforms} {\textbar} {Prefect}},
	url = {https://www.prefect.io/},
	abstract = {Prefect offers modern orchestration solutions to empower data teams to build resilient workflows that scale with versatile resource needs.},
	language = {en},
	urldate = {2025-02-23},
	annote = {Prefect
},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\XTK5RHCA\\www.prefect.io.html:text/html},
}

@article{coffey_fundamental_2000,
	title = {Fundamental limits for information retrieval},
	volume = {46},
	issn = {1557-9654},
	url = {https://ieeexplore.ieee.org/abstract/document/887844},
	doi = {10.1109/18.887844},
	abstract = {The fundamental limits of performance for a general model of information retrieval from databases are studied. In the scenarios considered, a large quantity of information is to be stored on some physical storage device. Requests for information are modeled as a randomly generated sequence with a known distribution. The requests are assumed to be "context-dependent," i.e., to vary according to the sequence of previous requests. The state of the physical storage device is also assumed to depend on the history of previous requests. In general, the logical structure of the information to be stored does not match the physical structure of the storage device, and consequently there are nontrivial limits on the minimum achievable average access times, where the average is over the possible sequences of user requests. The paper applies basic information-theoretic methods to establish these limits and demonstrates constructive procedures that approach them, for a wide class of systems. Allowing redundancy greatly lowers the achievable access times, even when the amount added is an arbitrarily small fraction of the total amount of information in the database. The achievable limits both with and without redundancy are computed; in the case where redundancy is allowed the limits essentially coincide with lower limits for more general storage systems.},
	number = {7},
	urldate = {2025-05-15},
	journal = {IEEE Transactions on Information Theory},
	author = {Coffey, J.T. and Klimesh, M.},
	month = nov,
	year = {2000},
	keywords = {Information retrieval},
	pages = {2281--2298},
	annote = {Los métodos convencionales para la organización y búsqueda de archivos digitales se basan en gran medida en metadatos explícitos, como nombres de archivo, fechas o etiquetas manuales. Sin embargo, estas aproximaciones tienen limitaciones significativas:
},
	file = {Full Text PDF:C\:\\Users\\Neko\\Zotero\\storage\\DKNR8TUA\\Coffey y Klimesh - 2000 - Fundamental limits for information retrieval.pdf:application/pdf},
}

@misc{noauthor_welcome_2025,
	title = {Welcome {Gemma} 3: {Google}'s all new multimodal, multilingual, long context open {LLM}},
	shorttitle = {Welcome {Gemma} 3},
	url = {https://huggingface.co/blog/gemma3},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2025-05-23},
	month = mar,
	year = {2025},
}

@misc{noauthor_lmarena_nodate,
	title = {{LMArena Leaderboard}},
	url = {https://beta.lmarena.ai/leaderboard},
	abstract = {An open platform for evaluating AI through human preference},
	language = {en},
	urldate = {2025-05-23},
	journal = {LMArena},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\23SF3LVW\\leaderboard.html:text/html},
}

@misc{noauthor_gemma_nodate,
	title = {Gemma 3: {A} {27B} {Multimodal} {LLM} {Better} {Than} {Really} {Big} {Models} {\textbar} by {Elmo} {\textbar} {Medium}},
	url = {https://medium.com/@elmo92/gemma-3-a-27b-multimodal-llm-better-than-really-big-models-b4fe0f4949b4},
	urldate = {2025-05-23},
	file = {Gemma 3\: A 27B Multimodal LLM Better Than Really Big Models | by Elmo | Medium:C\:\\Users\\Neko\\Zotero\\storage\\SARRY6DM\\gemma-3-a-27b-multimodal-llm-better-than-really-big-models-b4fe0f4949b4.html:text/html},
}

@misc{noauthor_voyage_nodate,
	title = {Voyage {AI} {\textbar} {Home}},
	url = {https://www.voyageai.com/},
	abstract = {Voyage AI provides cutting-edge embedding models and rerankers for search and retrieval},
	language = {en},
	urldate = {2025-05-23},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\FEU3AKP4\\www.voyageai.com.html:text/html},
}

@misc{noauthor_advanced_nodate,
	title = {Advanced {RAG} {Techniques}: {An} {Overview}},
	shorttitle = {Advanced {RAG} {Techniques}},
	url = {https://www.linkedin.com/pulse/advanced-rag-techniques-overview-yugank-aman-t4kkf},
	abstract = {A comprehensive study of the advanced retrieval augmented generation techniques and algorithms, systemizing various approaches. Intro If you are familiar with the RAG concept, please skip to the Advanced RAG part.},
	language = {es},
	urldate = {2025-05-23},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\NA9NIMLM\\advanced-rag-techniques-overview-yugank-aman-t4kkf.html:text/html},
}

@misc{noauthor_multi-modal_nodate,
	title = {Multi-modal {ML} with {OpenAI}'s {CLIP} {\textbar} {Pinecone}},
	url = {https://www.pinecone.io/learn/series/image-search/clip/},
	abstract = {Multi-modality and the future of computer vision with OpenAI's CLIP.},
	language = {en},
	urldate = {2025-05-23},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\HA6HYYC2\\clip.html:text/html},
}

@misc{noauthor_semantic_nodate,
	title = {Semantic {Content} {Discovery} for a {Post}-{Production} {World} - {Twelve} {Labs}},
	url = {https://www.twelvelabs.io/blog/twelve-labs-and-avid},
	urldate = {2025-05-23},
	file = {Semantic Content Discovery for a Post-Production World - Twelve Labs:C\:\\Users\\Neko\\Zotero\\storage\\QW2HJFL4\\twelve-labs-and-avid.html:text/html},
}

@misc{mahboub_evaluation_2024,
	title = {Evaluation of {Semantic} {Search} and its {Role} in {Retrieved}-{Augmented}-{Generation} ({RAG}) for {Arabic} {Language}},
	url = {http://arxiv.org/abs/2403.18350},
	doi = {10.48550/arXiv.2403.18350},
	abstract = {The latest advancements in machine learning and deep learning have brought forth the concept of semantic similarity, which has proven immensely beneficial in multiple applications and has largely replaced keyword search. However, evaluating semantic similarity and conducting searches for a specific query across various documents continue to be a complicated task. This complexity is due to the multifaceted nature of the task, the lack of standard benchmarks, whereas these challenges are further amplified for Arabic language. This paper endeavors to establish a straightforward yet potent benchmark for semantic search in Arabic. Moreover, to precisely evaluate the effectiveness of these metrics and the dataset, we conduct our assessment of semantic search within the framework of retrieval augmented generation (RAG).},
	urldate = {2025-05-23},
	publisher = {arXiv},
	author = {Mahboub, Ali and Za'ter, Muhy Eddin and Al-Rfooh, Bashar and Estaitia, Yazan and Jaljuli, Adnan and Hakouz, Asma},
	month = may,
	year = {2024},
	note = {arXiv:2403.18350 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Full Text PDF:C\:\\Users\\Neko\\Zotero\\storage\\9RQT6WJV\\Mahboub et al. - 2024 - Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Langua.pdf:application/pdf;Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\TXRGQXT6\\2403.html:text/html},
}

@misc{islas_expert_2023,
	title = {Expert {Analysis}: {Keyword} {Search} vs {Semantic} {Search} - {Part} {One}},
	shorttitle = {Expert {Analysis}},
	url = {https://enterprise-knowledge.com/expert-analysis-keyword-search-vs-semantic-search-part-one/},
	abstract = {Keyword search has been the predominant method to provide search to an enterprise application; however, semantic search has recently gained wider acceptance as a plausible alternative to the former.},
	language = {en-US},
	urldate = {2025-05-23},
	journal = {Enterprise Knowledge},
	author = {Islas, Fernando Aguilar, Chris Marino},
	month = mar,
	year = {2023},
}

@misc{noauthor_top_2023,
	title = {Top {Large} {Language} {Models} ({LLMs}): {GPT}-4, {LLaMA} 2, {Mistral} {7B}, {ChatGPT}, and {More}},
	shorttitle = {Top {Large} {Language} {Models} ({LLMs})},
	url = {https://www.vectara.com/blog/top-large-language-models-llms-gpt-4-llama-gato-bloom-and-when-to-choose-one-over-the-other},
	language = {en},
	urldate = {2025-05-23},
	journal = {Vectara},
	month = oct,
	year = {2023},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\CW4L7BDU\\top-large-language-models-llms-gpt-4-llama-gato-bloom-and-when-to-choose-one-over-the-other.html:text/html},
}

@misc{noauthor_moondream_nodate,
	title = {Moondream},
	url = {https://moondream.ai/},
	urldate = {2025-05-23},
	file = {Moondream:C\:\\Users\\Neko\\Zotero\\storage\\F3BR5ML3\\moondream.ai.html:text/html},
}

@article{yenigalla_implementation_2023,
	title = {Implementation of {Content}-{Based} {Image} {Retrieval} {Using} {Artificial} {Neural} {Networks}},
	volume = {34},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2673-4591},
	url = {https://www.mdpi.com/2673-4591/34/1/25},
	doi = {10.3390/HMAM2-14161},
	abstract = {CBIR (Content Based Image Retrieval) has become a critical domain in the previous decade, owing to the rising demand for image retrieval from multimedia databases. Typically, we take low-level (colour, texture and shape) or high-level (when machine learning techniques are used) features out of the photos. In our research, we examine the CBIR system utilising three machine learning methods, namely SVM (Support Vector Machine), KNN (K Nearest Neighbours), and CNN (Convolution Neural Networks), using Corel 1K, 5K, and 10K databases, by splitting the data into 80\% train data and 20\% test data. Moreover, compare each algorithm’s accuracy and efficiency when a specific task of image retrieval is given to it. The final outcome of this project will provide us with a clear vision of how effective deep learning, KNN and CNN algorithms are to finish the task of image retrieval.},
	language = {en},
	number = {1},
	urldate = {2025-05-23},
	journal = {Engineering Proceedings},
	author = {Yenigalla, Sarath Chandra and Rao, Karumuri Srinivasa and Ngangbam, Phalguni Singh},
	year = {2023},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Content Based Image Retrieval, Convolution Neural Networks, deep learning},
	pages = {25},
	file = {Full Text PDF:C\:\\Users\\Neko\\Zotero\\storage\\UM78J3I6\\Yenigalla et al. - 2023 - Implementation of Content-Based Image Retrieval Using Artificial Neural Networks.pdf:application/pdf},
}

@misc{noauthor_why_nodate,
	title = {Why {Build} {RAG} with {Local} {Data}? {A} {Developer}\&\#39;s {Guide} to {Private} {AI}},
	shorttitle = {Why {Build} {RAG} with {Local} {Data}?},
	url = {https://www.puppyagent.com/blog/Build-RAG-with-Local-Data-Developer-Guide-to-Private-AI},
	abstract = {Read our latest blog posts about AI knowledge base and RAG.},
	language = {en},
	urldate = {2025-05-23},
	journal = {PuppyAgent},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\3KNXDEUF\\Build-RAG-with-Local-Data-Developer-Guide-to-Private-AI.html:text/html},
}

@misc{noauthor_rag_nodate,
	title = {{RAG} vs {Large} {Context} {Window} {LLMs}: {When} to use which one?},
	shorttitle = {{RAG} vs {Large} {Context} {Window} {LLMs}},
	url = {https://www.thecloudgirl.dev/blog/rag-vs-large-context-window},
	abstract = {Large language models (LLMs) are constantly evolving, and one key area of development is how much context they can consider when generating text. Large language models (LLMs) are incredibly powerful tools for processing and generating text. However, they inherently struggle to understand the broader},
	language = {en-US},
	urldate = {2025-05-23},
	journal = {The Cloud Girl},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\MHHFZ6UL\\rag-vs-large-context-window.html:text/html},
}

@misc{tong_multimodal_2024,
	title = {Multimodal search: {Searching} with semantic and visual understanding},
	shorttitle = {Multimodal search},
	url = {https://opensearch.org/blog/multimodal-semantic-search/},
	abstract = {As we witness the evolution of ML models, like large language models (LLMs), imagine if they possessed a new dimension – the ability to comprehend images. Similar to the game-changing...},
	language = {en-US},
	urldate = {2025-05-23},
	journal = {OpenSearch},
	author = {Tong, Hao and Yang, Dylan and Martin, Gaievski},
	month = apr,
	year = {2024},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\EM5TR64I\\multimodal-semantic-search.html:text/html},
}
