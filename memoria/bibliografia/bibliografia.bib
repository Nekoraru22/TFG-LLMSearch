
@misc{thomas_janssen_build_2024,
	title = {Build a {RAG} in 10 minutes! {\textbar} {Python}, {ChromaDB}, {OpenAI}},
	url = {https://www.youtube.com/watch?v=JfSmffOyV-8},
	urldate = {2025-04-22},
	author = {{Thomas Janssen}},
	month = aug,
	year = {2024},
}

@misc{multani_mickymultanirag-chromadb-mistral7b_2025,
	title = {mickymultani/{RAG}-{ChromaDB}-{Mistral7B}},
	url = {https://github.com/mickymultani/RAG-ChromaDB-Mistral7B},
	abstract = {RAG (Retrievel Augmented Generation) implementation using ChromaDB, Mistral-7B-Instruct-v0.1 and gte-base for embeddings.},
	urldate = {2025-04-22},
	author = {Multani, Micky},
	month = feb,
	year = {2025},
	note = {original-date: 2023-10-01T19:25:31Z},
}

@misc{noauthor_que_nodate,
	title = {¿{Qué} es {RAG}?: explicación de la {IA} de generación aumentada por recuperación, {AWS}},
	shorttitle = {¿{Qué} es {RAG}?},
	url = {https://aws.amazon.com/es/what-is/retrieval-augmented-generation/},
	abstract = {Qué es la Retrieval-Augmented Generation (RAG, generación aumentada por recuperación), cómo y por qué las empresas usan IA de RAG y cómo usar RAG con AWS.},
	language = {es-ES},
	urldate = {2025-04-07},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\ZWGN2CK7\\retrieval-augmented-generation.html:text/html},
}

@misc{noauthor_lmstudio-python_nodate,
	title = {lmstudio-python ({Python} {SDK}) {\textbar} {LM} {Studio} {Docs}},
	url = {https://lmstudio.ai/docs/python},
	abstract = {Getting started with LM Studio's Python SDK},
	language = {en},
	urldate = {2025-03-31},
	journal = {LM Studio - Docs},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\AHQWUCLT\\python.html:text/html},
}

@misc{noauthor_lm_nodate,
	title = {{LM} {Studio} - {Discover}, download, and run local {LLMs}},
	url = {https://lmstudio.ai},
	abstract = {Run Llama, Gemma 3, DeepSeek locally on your computer.},
	language = {en},
	urldate = {2025-03-31},
	journal = {LM Studio},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\ZVYYKYXY\\lmstudio.ai.html:text/html},
}

@misc{noauthor_mongodb_nodate,
	title = {{MongoDB} {Atlas}: {Cloud} {Document} {Database}},
	shorttitle = {{MongoDB} {Atlas}},
	url = {https://www.mongodb.com/es/lp/cloud/atlas/try4},
	abstract = {Cloud-hosted MongoDB service on AWS, Azure, and GCP},
	language = {es},
	urldate = {2025-02-23},
	journal = {MongoDB},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\C6QX8EJD\\try4.html:text/html},
}

@misc{noauthor_sqlite_nodate,
	title = {{SQLite} {Home} {Page}},
	url = {https://www.sqlite.org/},
	urldate = {2025-02-23},
	file = {SQLite Home Page:C\:\\Users\\Neko\\Zotero\\storage\\WPYU9XRI\\www.sqlite.org.html:text/html},
}

@misc{noauthor_watchdog_nodate,
	title = {watchdog: {Filesystem} events monitoring},
	copyright = {OSI Approved :: Apache Software License},
	shorttitle = {watchdog},
	url = {https://github.com/gorakhargosh/watchdog},
	urldate = {2025-02-23},
	keywords = {DirectorySnapshot, filesystem,, FSEvents,, inotify,, kqueue,, monitor,, monitoring,, polling,, python,, ReadDirectoryChangesW,, Software Development - Libraries, System - Filesystems, System - Monitoring, Utilities},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\HBVV8XXY\\watchdog.html:text/html},
}

@misc{noauthor_home_nodate,
	title = {Home},
	url = {https://airflow.apache.org/},
	abstract = {Platform created by the community to programmatically author, schedule and monitor workflows.},
	language = {en},
	urldate = {2025-02-23},
	journal = {Apache Airflow},
	annote = {Airflow
},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\ALQ9QV27\\airflow.apache.org.html:text/html},
}

@misc{noauthor_apache_nodate,
	title = {Apache {Kafka}},
	url = {https://kafka.apache.org/documentation/},
	abstract = {Apache Kafka: A Distributed Streaming Platform.},
	language = {en},
	urldate = {2025-02-23},
	journal = {Apache Kafka},
	annote = {Kafka
},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\DCHAER4Z\\documentation.html:text/html},
}

@misc{noauthor_best_2024,
	title = {Best {ML} {Workflow} and {Pipeline} {Orchestration} {Tools} 2024},
	url = {https://dagshub.com/blog/best-machine-learning-workflow-and-pipeline-orchestration-tools/},
	abstract = {Explore the top ML workflow and pipeline tools, including tools from Netflix, to enhance your data science projects' efficiency and impact.},
	language = {en},
	urldate = {2025-02-23},
	journal = {DagsHub Blog},
	month = apr,
	year = {2024},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\HLKWT5A4\\best-machine-learning-workflow-and-pipeline-orchestration-tools.html:text/html},
}

@misc{suspicious_dress_350_airflow_2024,
	type = {Reddit {Post}},
	title = {Airflow vs {Dagster} vs {Prefect} vs ?},
	url = {https://www.reddit.com/r/dataengineering/comments/1cxyvqk/airflow_vs_dagster_vs_prefect_vs/},
	urldate = {2025-02-23},
	journal = {r/dataengineering},
	author = {Suspicious\_Dress\_350},
	month = may,
	year = {2024},
	file = {Reddit Post Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\M8TSAM3C\\airflow_vs_dagster_vs_prefect_vs.html:text/html},
}

@misc{noauthor_home_0800,
	title = {Home},
	url = {https://docs.docker.com/},
	abstract = {Docker Documentation is the official Docker library of resources, manuals, and guides to help you containerize applications.},
	language = {en},
	urldate = {2025-02-23},
	journal = {Docker Documentation},
	year = {0800},
	annote = {Docker
},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\A55A6T9A\\docs.docker.com.html:text/html},
}

@misc{noauthor_pythonic_nodate,
	title = {Pythonic, {Modern} {Workflow} {Orchestration} {For} {Resilient} {Data} {Platforms} {\textbar} {Prefect}},
	url = {https://www.prefect.io/},
	abstract = {Prefect offers modern orchestration solutions to empower data teams to build resilient workflows that scale with versatile resource needs.},
	language = {en},
	urldate = {2025-02-23},
	annote = {Prefect
},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\XTK5RHCA\\www.prefect.io.html:text/html},
}

@article{coffey_fundamental_2000,
	title = {Fundamental limits for information retrieval},
	volume = {46},
	issn = {1557-9654},
	url = {https://ieeexplore.ieee.org/abstract/document/887844},
	doi = {10.1109/18.887844},
	abstract = {The fundamental limits of performance for a general model of information retrieval from databases are studied. In the scenarios considered, a large quantity of information is to be stored on some physical storage device. Requests for information are modeled as a randomly generated sequence with a known distribution. The requests are assumed to be "context-dependent," i.e., to vary according to the sequence of previous requests. The state of the physical storage device is also assumed to depend on the history of previous requests. In general, the logical structure of the information to be stored does not match the physical structure of the storage device, and consequently there are nontrivial limits on the minimum achievable average access times, where the average is over the possible sequences of user requests. The paper applies basic information-theoretic methods to establish these limits and demonstrates constructive procedures that approach them, for a wide class of systems. Allowing redundancy greatly lowers the achievable access times, even when the amount added is an arbitrarily small fraction of the total amount of information in the database. The achievable limits both with and without redundancy are computed; in the case where redundancy is allowed the limits essentially coincide with lower limits for more general storage systems.},
	number = {7},
	urldate = {2025-05-15},
	journal = {IEEE Transactions on Information Theory},
	author = {Coffey, J.T. and Klimesh, M.},
	month = nov,
	year = {2000},
	keywords = {Information retrieval},
	pages = {2281--2298},
	annote = {Los métodos convencionales para la organización y búsqueda de archivos digitales se basan en gran medida en metadatos explícitos, como nombres de archivo, fechas o etiquetas manuales. Sin embargo, estas aproximaciones tienen limitaciones significativas:
},
	file = {Full Text PDF:C\:\\Users\\Neko\\Zotero\\storage\\DKNR8TUA\\Coffey y Klimesh - 2000 - Fundamental limits for information retrieval.pdf:application/pdf},
}

@misc{noauthor_welcome_2025,
	title = {Welcome {Gemma} 3: {Google}'s all new multimodal, multilingual, long context open {LLM}},
	shorttitle = {Welcome {Gemma} 3},
	url = {https://huggingface.co/blog/gemma3},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2025-05-23},
	month = mar,
	year = {2025},
}

@misc{noauthor_lmarena_nodate,
	title = {{LMArena Leaderboard}},
	url = {https://beta.lmarena.ai/leaderboard},
	abstract = {An open platform for evaluating AI through human preference},
	language = {en},
	urldate = {2025-05-23},
	journal = {LMArena},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\23SF3LVW\\leaderboard.html:text/html},
}

@misc{noauthor_gemma_nodate,
	title = {Gemma 3: {A} {27B} {Multimodal} {LLM} {Better} {Than} {Really} {Big} {Models} {\textbar} by {Elmo} {\textbar} {Medium}},
	url = {https://medium.com/@elmo92/gemma-3-a-27b-multimodal-llm-better-than-really-big-models-b4fe0f4949b4},
	urldate = {2025-05-23},
	file = {Gemma 3\: A 27B Multimodal LLM Better Than Really Big Models | by Elmo | Medium:C\:\\Users\\Neko\\Zotero\\storage\\SARRY6DM\\gemma-3-a-27b-multimodal-llm-better-than-really-big-models-b4fe0f4949b4.html:text/html},
}

@misc{noauthor_voyage_nodate,
	title = {Voyage {AI} {\textbar} {Home}},
	url = {https://www.voyageai.com/},
	abstract = {Voyage AI provides cutting-edge embedding models and rerankers for search and retrieval},
	language = {en},
	urldate = {2025-05-23},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\FEU3AKP4\\www.voyageai.com.html:text/html},
}

@misc{noauthor_advanced_nodate,
	title = {Advanced {RAG} {Techniques}: {An} {Overview}},
	shorttitle = {Advanced {RAG} {Techniques}},
	url = {https://www.linkedin.com/pulse/advanced-rag-techniques-overview-yugank-aman-t4kkf},
	abstract = {A comprehensive study of the advanced retrieval augmented generation techniques and algorithms, systemizing various approaches. Intro If you are familiar with the RAG concept, please skip to the Advanced RAG part.},
	language = {es},
	urldate = {2025-05-23},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\NA9NIMLM\\advanced-rag-techniques-overview-yugank-aman-t4kkf.html:text/html},
}

@misc{noauthor_multi-modal_nodate,
	title = {Multi-modal {ML} with {OpenAI}'s {CLIP} {\textbar} {Pinecone}},
	url = {https://www.pinecone.io/learn/series/image-search/clip/},
	abstract = {Multi-modality and the future of computer vision with OpenAI's CLIP.},
	language = {en},
	urldate = {2025-05-23},
	file = {Snapshot:C\:\\Users\\Neko\\Zotero\\storage\\HA6HYYC2\\clip.html:text/html},
}
